{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Note: this code is written as an assignment in a Helsinki Uni course on Deep Learning and is heavily influenced by\n",
    "#starter code provided by the lecturers Hande Celikkanat and Roman Yangarber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Got a working training session from start to finish\n",
    "#Good result but this used pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already has folders 'annotations' and 'images'.\n",
      "Assuming you already have the data and skipping fetch.\n"
     ]
    }
   ],
   "source": [
    "#Custom functions to read in our data from internet\n",
    "#Skips if data already exists\n",
    "\n",
    "from src import data_download\n",
    "data_download.fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#These are custom made functions to handle our data\n",
    "#Maybe more documentation later\n",
    "#The function used here can split our data to different sets\n",
    "\n",
    "from src import data_handling\n",
    "train, test, val = data_handling.get_target_dfs(train=0.6, test=0.2, val=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this code is an edited version of the code found at https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, labels_df, img_dir, transform=None, transform_rate=0.1):\n",
    "        self.img_labels = labels_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.transform_rate = transform_rate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_idx = self.img_labels.index[idx]\n",
    "        img_path = os.path.join(self.img_dir, \"im\"+str(img_idx)+\".jpg\")\n",
    "        image = read_image(img_path, ImageReadMode.RGB)#.float()\n",
    "        labels = torch.from_numpy(self.img_labels.iloc[idx].values).float()\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.to(\"cuda\")\n",
    "            labels = labels.to(\"cuda\")\n",
    "        if self.transform:\n",
    "            image = self._random_transform(image)\n",
    "        image = image.float()\n",
    "        return image, labels\n",
    "    \n",
    "    def _random_transform(self, image):\n",
    "        for transform in self.transform:\n",
    "            if random.random() < self.transform_rate:\n",
    "                image = transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Info About Custom Dataset:\n",
    "\n",
    "## Using Data and Indexing System:\n",
    "#The label data is kept in one-hotted Pandas dataframe \"labels_df\". This does not contain the image data. Label data is fairly small so can be kept directly in memory.\n",
    "#Dataframes have two indexing systems. Hidden internal index (iloc, or .index[]), which always goes from 0 to len-1.\n",
    "#Second indexing system is the visible index, which might be different. For our dataframe, the visible index follows image indexing, which can be used to load in image data.\n",
    "#Pytorch DataLoaders call dataset __getitem__ method with idx values from 0 to __len__()-1. This corresponds to our dataframe hidden indexing.\n",
    "#For one item within __getitem__ method, we are dealing with a single in our dataframe\n",
    "#To get image index from hidden index we set img_idx = self.img_labels.index[idx]. This is used to get image data for the item.\n",
    "#Corresponding one-hotted label data is obtained with hidden index: self.img_labels.iloc[idx].values\n",
    "\n",
    "## Reading Image\n",
    "#We use torchvision read_image method\n",
    "#We force every image to be read in as color images with ImageReadMode.RGB\n",
    "#This way every image has 3 channels, otherwise gray images have 1 channels and Dataloader fails\n",
    "#Other way would be to grayscale everything\n",
    "\n",
    "## Other\n",
    "#Additional image transformers in self.transform are only applied if they exists (not None)\n",
    "#For now it is hardcoded in that the data get sent to cuda device. If there's no cuda available, this class most likely fails. Maybe I'll turn this to dynamic version later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_mix = [transforms.ColorJitter(brightness=.5, hue=.3), transforms.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
    "                transforms.RandomAdjustSharpness(sharpness_factor=2)]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=CustomImageDataset(train, DATA_DIR, transform=transform_mix), batch_size=50, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=CustomImageDataset(test, DATA_DIR, transform=None), batch_size=50, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=CustomImageDataset(val, DATA_DIR, transform=None), batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is a pretrained base-model\n",
    "#DEFAULT weights = \"best\" weights\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The rest of the code is a pretty standard simple Pytorch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, num_labels=14):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        self.base_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1000, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_labels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.base_model(x)\n",
    "        out = self.classifier(features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#added a simple home-made CNN for comparing to resnet\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=14, dropout_rate=0.1):\n",
    "        super(CNN, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.05)\n",
    "        self.features = nn.Sequential(\n",
    "          nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "          nn.BatchNorm2d(16),\n",
    "          nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "          nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        self.classify = nn.Sequential(\n",
    "          nn.Linear(32 * 32 * 32, 60),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(p=dropout_rate),\n",
    "          nn.Linear(60, num_classes),\n",
    "          nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"forwarding\")\n",
    "        x = self.features(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 32 * 32 * 32)\n",
    "        x = self.classify(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cuda device\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Found cuda device\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#comment out the model you don't want to use\n",
    "#model = MultiLabelClassifier().to(device)\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 1 done. Training loss 0.776\n",
      "Validation accuracy was: 0.9281535671081071\n",
      "Epoch 2\n",
      "Epoch 2 done. Training loss 0.698\n",
      "Validation accuracy was: 0.9283163672612037\n",
      "Epoch 3\n",
      "Epoch 3 done. Training loss 0.695\n",
      "Validation accuracy was: 0.9282512414602586\n",
      "Postponing early-stopping\n",
      "Epoch 4\n",
      "Epoch 4 done. Training loss 0.694\n",
      "Validation accuracy was: 0.9282186840787346\n",
      "Breaking loop due to early-stopping\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "early_stop_patience = 1 # How many epochs to go without improvement\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "postpone_early_stop = early_stop_patience\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train() #Enables dropout layer\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    total = 0\n",
    "    for batch_num, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} done. Training loss {train_loss/(batch_num+1):.3f}\")\n",
    "    \n",
    "    ### VALIDATION\n",
    "    model.eval() #Disables dropout layer\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (inputs, labels) in enumerate(val_loader):\n",
    "            outputs = model(inputs)\n",
    "            predicted_labels = (outputs > 0.5).int()\n",
    "            val_accuracy += (predicted_labels == labels).float().mean().item()\n",
    "    val_accuracy = val_accuracy / len(val_loader)\n",
    "    print(f\"Validation accuracy was: {val_accuracy}\")\n",
    "    \n",
    "    ### EARLY STOP\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        postpone_early_stop = early_stop_patience #Reset patience\n",
    "        torch.save(model.state_dict(), 'best_model_state.pt') #Save best model state\n",
    "        continue\n",
    "        \n",
    "    #allowing for some epoch to have worse accuracy than the one before\n",
    "    elif postpone_early_stop > 0:\n",
    "        postpone_early_stop -= 1 \n",
    "        print(\"Postponing early-stopping\")\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Breaking loop due to early-stopping\")\n",
    "        model.load_state_dict(torch.load('best_model_state.pt'))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.927\n"
     ]
    }
   ],
   "source": [
    "#The output returns a probability array for every label\n",
    "#Probability is the probability of label=1 (image has the specific label)\n",
    "#These are turned to actual predictions with predicted_labels = (outputs > 0.5).int()\n",
    "#This means that if it's more likely than not that image has a certain label, then it gets assigned the label\n",
    "#Otherwise the image will not have the label\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval() #Disables dropout layer\n",
    "    accuracy = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted_labels = (outputs > 0.5).int()\n",
    "        accuracy += (predicted_labels == labels).float().mean().item()\n",
    "accuracy = accuracy / len(test_loader)\n",
    "print(f\"Test accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note about predictions:\n",
    "#We're not actually told whats the exact evaluation metric for \"competition\"\n",
    "#Is it the one used here? So for every every label a predicion of 0 or 1\n",
    "#Could be also that missed labels get penalized differently than extra labels not in ground truth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b00c71c3385904d38907326321bc6ca9930b9cd405025156e2f0e2cd3cac88e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
