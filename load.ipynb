{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Note: this code is written as an assignment in a Helsinki Uni course on Deep Learning and is heavily influenced by\n",
    "#starter code provided by the lecturers Hande Celikkanat and Roman Yangarber\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already has folders 'annotations' and 'images'.\n",
      "Assuming you already have the data and skipping fetch.\n"
     ]
    }
   ],
   "source": [
    "#DATA SHOULD BE IN \"data/\" folder NOW\n",
    "#HERES HOW TO DOWNLOAD DATA DIRECTLY (should skip if already has data):\n",
    "from src import data\n",
    "data.fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "(20000, 14)\n"
     ]
    }
   ],
   "source": [
    "annotations = os.listdir('./data/annotations')\n",
    "#print([x.split('.')[0] for x in annotations])\n",
    "images = os.listdir('./data/images')\n",
    "print(len(images))\n",
    "df = pd.DataFrame(0, index=np.arange(1,len(images)+1), columns=[x.split('.')[0] for x in annotations])\n",
    "print(df.shape)\n",
    "for tag in annotations:\n",
    "    with open(f'./data/annotations/{tag}') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "           imgNumber = line.split(\"\\n\")[0]\n",
    "           df[tag.split('.')[0]][int(imgNumber)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.Grayscale()])\n",
    "test_transform = transforms.Compose([transforms.Grayscale()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this code is an edited version of the code found at https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_df, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = annotations_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, \"im\"+str(idx+1)+\".jpg\")\n",
    "        image = Image.open(img_path)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Grayscale()\n",
    "            #transforms.RandomResizedCrop(256)\n",
    "        ])\n",
    "        img_tensor = transform(image)\n",
    "        label = torch.from_numpy(np.array(self.img_labels.iloc[idx])).float()#NOTE! This should be fixed (the float issue)\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return img_tensor, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customImageDataset = CustomImageDataset(df, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=customImageDataset, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(CNN, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.05)\n",
    "        self.features = nn.Sequential(\n",
    "          nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "          nn.BatchNorm2d(16),\n",
    "          nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "          nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        self.classify = nn.Sequential(\n",
    "          nn.Linear(32 * 32 * 32, 60),\n",
    "          nn.Linear(60, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 32 * 32 * 32)\n",
    "        x = self.classify(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classify): Sequential(\n",
      "    (0): Linear(in_features=32768, out_features=60, bias=True)\n",
      "    (1): Linear(in_features=60, out_features=14, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN(NUM_CLASSES)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6644041538238525\n",
      "Training: Epoch 0 - Batch 0/400: Loss: 2.6644 \n",
      "2.6997636556625366\n",
      "Training: Epoch 0 - Batch 1/400: Loss: 2.6998 \n",
      "2.5542126496632895\n",
      "Training: Epoch 0 - Batch 2/400: Loss: 2.5542 \n",
      "2.5714571475982666\n",
      "Training: Epoch 0 - Batch 3/400: Loss: 2.5715 \n",
      "2.7193463802337647\n",
      "Training: Epoch 0 - Batch 4/400: Loss: 2.7193 \n",
      "2.7184336185455322\n",
      "Training: Epoch 0 - Batch 5/400: Loss: 2.7184 \n",
      "2.8261242594037737\n",
      "Training: Epoch 0 - Batch 6/400: Loss: 2.8261 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    total = 0\n",
    "    for batch_num, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        result = model.forward(data)\n",
    "        probs = torch.softmax(result, dim=1)\n",
    "        #print(probs)\n",
    "        #winners = probs.argmax(dim=1)\n",
    "        #print(winners)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(result, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        print(train_loss / (batch_num+1))\n",
    "        print('Training: Epoch %d - Batch %d/%d: Loss: %.4f ' % \n",
    "              (epoch, batch_num, len(train_loader), train_loss / (batch_num + 1)))\n",
    "        #train_correct += (winners == target).sum().item()\n",
    "        #total = total + BATCH_SIZE_TRAIN\n",
    "        #print('Training: Epoch %d - Batch %d/%d: Loss: %.4f | Train Acc: %.3f%% (%d/%d)' % \n",
    "        #      (epoch, batch_num, len(train_loader), train_loss / (batch_num + 1), \n",
    "        #       100. * train_correct / total, train_correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b00c71c3385904d38907326321bc6ca9930b9cd405025156e2f0e2cd3cac88e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
